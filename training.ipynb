{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "dDLYS2xJYQ6l"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "ft25hGgZYQ6o",
    "outputId": "34c17ee8-5b82-47e7-fc2d-cbb9bfb89b10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\r\n",
      "\u001b[K     |████████████████████████████████| 450kB 2.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from transformers) (4.39.0)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers) (0.1.83)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.10.29)\r\n",
      "Collecting sacremoses\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\r\n",
      "\u001b[K     |████████████████████████████████| 860kB 8.9MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers) (1.17.4)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2019.11.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.22.0)\r\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.29 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (1.13.29)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers) (0.2.1)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.13.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.0)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.24.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.8)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\r\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.29->boto3->transformers) (2.8.0)\r\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.29->boto3->transformers) (0.15.2)\r\n",
      "Building wheels for collected packages: sacremoses\r\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=8ea59287501ca06f879641dafb1ece9da09adf7d662e9fcbe738f39a92a78eac\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\r\n",
      "Successfully built sacremoses\r\n",
      "Installing collected packages: sacremoses, transformers\r\n",
      "Successfully installed sacremoses-0.0.35 transformers-2.3.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "LreMa21WYQ60",
    "outputId": "16b57e05-3859-4da7-d784-d0f9309ebf4e"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egoYyBasYQ62"
   },
   "outputs": [],
   "source": [
    "path_to_dataset = '/kaggle/input/nlp-getting-started/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60yz6umrYQ65"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.path.join(path_to_dataset, 'test.csv'))\n",
    "train = pd.read_csv(os.path.join(path_to_dataset, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mUsu0OnYQ7L"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uvKfV5xVYQ7Q"
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.base_model = BertModel.from_pretrained('bert-base-uncased') # use pre-trained BERT model by HuggingFace\n",
    "        self.fc1 = torch.nn.Linear(768, 1) # simple logistic regression above the bert model\n",
    "        \n",
    "    def forward(self, ids, masks):\n",
    "        \n",
    "        x = self.base_model(ids, attention_mask=masks)[1]\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RxtBVRzYQ7U"
   },
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9jYAk2tYQ7a"
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hu0G6gWPYQ7g"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D25GxDlnYQ7l"
   },
   "outputs": [],
   "source": [
    "def bert_encode(text, max_len=512):\n",
    "    \n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = text[:max_len-2]\n",
    "    input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "    tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "    tokens += [0] * (max_len - len(input_sequence))\n",
    "    pad_masks = [1] * len(input_sequence) + [0] * (max_len - len(input_sequence))\n",
    "\n",
    "    return tokens, pad_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fJiZDy_YQ7o"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9] \\n', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use first 6000 for training, rest for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXv4GsJpYQ7w"
   },
   "outputs": [],
   "source": [
    "train_text = train.text[:6000]\n",
    "val_text = train.text[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0CVkqo36YQ70"
   },
   "outputs": [],
   "source": [
    "train_text = train_text.apply(clean_text)\n",
    "val_text = val_text.apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrF1Zo-dYQ79"
   },
   "outputs": [],
   "source": [
    "train_tokens = []\n",
    "train_pad_masks = []\n",
    "for text in train_text:\n",
    "    tokens, masks = bert_encode(text)\n",
    "    train_tokens.append(tokens)\n",
    "    train_pad_masks.append(masks)\n",
    "    \n",
    "train_tokens = np.array(train_tokens)\n",
    "train_pad_masks = np.array(train_pad_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fQTuqiGYQ8D"
   },
   "outputs": [],
   "source": [
    "val_tokens = []\n",
    "val_pad_masks = []\n",
    "for text in val_text:\n",
    "    tokens, masks = bert_encode(text)\n",
    "    val_tokens.append(tokens)\n",
    "    val_pad_masks.append(masks)\n",
    "    \n",
    "val_tokens = np.array(val_tokens)\n",
    "val_pad_masks = np.array(val_pad_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yze74WnSYQ8G"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, train_tokens, train_pad_masks, targets):\n",
    "        \n",
    "        super(Dataset, self).__init__()\n",
    "        self.train_tokens = train_tokens\n",
    "        self.train_pad_masks = train_pad_masks\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tokens = self.train_tokens[index]\n",
    "        masks = self.train_pad_masks[index]\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        return (tokens, masks), target\n",
    "    \n",
    "    def __len__(self,):\n",
    "        \n",
    "        return len(self.train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-IoZpwYYQ8I"
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\n",
    "                    train_tokens=train_tokens,\n",
    "                    train_pad_masks=train_pad_masks,\n",
    "                    targets=train.target[:6000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbgDF9-sYQ8K"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Adam Optimizer with learning rate of 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBUVo0o4YQ8R"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MAn-sCjzYQ8W",
    "outputId": "295b32fc-0beb-4317-a806-375b1d190aa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2, 99.900000% loss: 0.49\n",
      "Epoch: 2/2, 99.900000% loss: 0.29\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "y_preds = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "        for i, ((tokens, masks), target) in enumerate(train_dataloader):\n",
    "\n",
    "            y_pred = model(\n",
    "                        tokens.long().to(device), \n",
    "                        masks.long().to(device)\n",
    "                    )\n",
    "            loss = criterion(y_pred, target[:, None].float().to(device))\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            print('\\rEpoch: %d/%d, %f%% loss: %0.2f'% (epoch+1, EPOCHS, i/len(train_dataloader)*100, loss.item()), end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft0-NpxmhJXq"
   },
   "outputs": [],
   "source": [
    "val_dataset = Dataset(\n",
    "                    train_tokens=val_tokens,\n",
    "                    train_pad_masks=val_pad_masks,\n",
    "                    targets=train.target[6000:].reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f0oq-S-DaADT"
   },
   "outputs": [],
   "source": [
    "val_dataloader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ve63qae4iDwh"
   },
   "outputs": [],
   "source": [
    "def accuracy(y_actual, y_pred):\n",
    "    y_ = y_pred > 0\n",
    "    return np.sum(y_actual == y_).astype('int') / y_actual.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QQplK689h5aU",
    "outputId": "b7dd9071-6156-4772-8114-81b7445668e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.81% loss: 0.01, accuracy 1.00\n",
      "Average accuracy:  0.8395291201982663\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "avg_acc = 0\n",
    "for i, ((tokens, masks), target) in enumerate(val_dataloader):\n",
    "\n",
    "    y_pred = model(\n",
    "                tokens.long().to(device), \n",
    "                masks.long().to(device), \n",
    "            )\n",
    "    loss = criterion(y_pred,  target[:, None].float().to(device))\n",
    "    acc = accuracy(target.cpu().numpy(), y_pred.detach().cpu().numpy().squeeze())\n",
    "    avg_acc += acc\n",
    "    print('\\r%0.2f%% loss: %0.2f, accuracy %0.2f'% (i/len(val_dataloader)*100, loss.item(), acc), end='')\n",
    "print('\\nAverage accuracy: ', avg_acc / len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ta_HjUOlkcoC"
   },
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, test_tokens, test_pad_masks):\n",
    "        \n",
    "        super(TestDataset, self).__init__()\n",
    "        self.test_tokens = test_tokens\n",
    "        self.test_pad_masks = test_pad_masks\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        tokens = self.test_tokens[index]\n",
    "        masks = self.test_pad_masks[index]\n",
    "        \n",
    "        return (tokens, masks)\n",
    "    \n",
    "    def __len__(self,):\n",
    "        \n",
    "        return len(self.test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxHhO1ShkwuE"
   },
   "outputs": [],
   "source": [
    "test_tokens = []\n",
    "test_pad_masks = []\n",
    "for text in test.text:\n",
    "    tokens, masks = bert_encode(text)\n",
    "    test_tokens.append(tokens)\n",
    "    test_pad_masks.append(masks)\n",
    "    \n",
    "test_tokens = np.array(test_tokens)\n",
    "test_pad_masks = np.array(test_pad_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2S0s7Mskceg"
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\n",
    "    test_tokens=test_tokens,\n",
    "    test_pad_masks=test_pad_masks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqNQdB7nkrwX"
   },
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "XWdtUf72lbeU",
    "outputId": "6df1b8a3-575c-4dc7-bfa8-e1409c0b4da9"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_preds = []\n",
    "for (tokens, masks) in test_dataloader:\n",
    "\n",
    "    y_pred = model(\n",
    "                tokens.long().to(device), \n",
    "                masks.long().to(device), \n",
    "            )\n",
    "    y_preds += y_pred.detach().cpu().numpy().squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mYhm2iiZl9Dr"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(os.path.join(path_to_dataset, 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQViCYQamCp4"
   },
   "outputs": [],
   "source": [
    "submission_df['target'] = (np.array(y_preds) > 0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "T2-2y6R5nDDp",
    "outputId": "e5aa08a2-280a-485b-dd69-7bccbf938ab9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2018\n",
       "1    1245\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "colab_type": "code",
    "id": "1XT7pT-smVlJ",
    "outputId": "0f2e9c14-2ffc-4d0d-f783-96b36e4670cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VLB7DwOzmYCq"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaJks0hknH4p"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "kernel69237ad76a.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
